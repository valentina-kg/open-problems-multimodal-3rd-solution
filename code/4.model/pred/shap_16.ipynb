{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "810b90c5",
   "metadata": {},
   "source": [
    "- load model #16\n",
    "- explainer = shap.KernelExplainer(model, X_train)\n",
    "- get shap_values = explainer.shap_values(X_test_shap)\n",
    "- save shap_values_16_n_samples.npy\\\n",
    "=> shap values for 212 features! 128 svd components + 84 handselected genes\n",
    "- same steps for model #17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e258c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture output\n",
    "!pip install --upgrade pip\n",
    "!pip install --upgrade pandas\n",
    "!pip install tables   \n",
    "# necessary for pd.read_hdf()\n",
    "\n",
    "!pip install ipywidgets\n",
    "!pip install --upgrade jupyter\n",
    "!pip install IProgress\n",
    "# !pip install catboost\n",
    "!pip install shap\n",
    "!pip install anndata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b58ec468",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shap\n",
    "\n",
    "import anndata as ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ca70601",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else 'cpu'\n",
    "# pd.set_option('display.max_rows', 500)\n",
    "# pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e24ab66",
   "metadata": {},
   "source": [
    "## data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7d9f9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrz_path = '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93zoj/open-problems-multimodal-3rd-solution/'\n",
    "\n",
    "# model_path_for_now = '/dss/dsshome1/02/di93zoj/valentina/open-problems-multimodal-3rd-solution/'\n",
    "\n",
    "raw_path =  lrz_path + 'input/raw/'  # '../../../input/raw/'\n",
    "\n",
    "cite_target_path = lrz_path + 'input/target/cite/'   # '../../../input/target/cite/'\n",
    "cite_feature_path = lrz_path + 'input/features/cite/'   # '../../../input/features/cite/'\n",
    "cite_mlp_path = lrz_path + 'model/cite/mlp/'   # '../../../model/cite/mlp/'   # '../../../model/cite/mlp/'\n",
    "cite_cb_path = lrz_path + 'model/cite/cb/'   # '../../../model/cite/cb/'\n",
    "\n",
    "# multi_target_path = lrz_path + 'input/target/multi/'   # '../../../input/target/multi/'\n",
    "# multi_feature_path = lrz_path + 'input/features/multi/'   # '../../../input/features/multi/'\n",
    "# multi_mlp_path = lrz_path + 'model/multi/mlp/'   # '../../../model/multi/mlp/'\n",
    "# multi_cb_path = lrz_path + 'model/multi/cb/'   # '../../../model/multi/cb/'\n",
    "\n",
    "index_path = lrz_path + 'input/preprocess/cite/'\n",
    "\n",
    "output_path = lrz_path + 'output/'   # '../../../output/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a14faf",
   "metadata": {},
   "source": [
    "## Cite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f2ea3bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get model name\n",
    "#mlp_model_path = os.listdir(cite_mlp_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "255e8ddf",
   "metadata": {},
   "source": [
    "markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c1d203d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check model names and lists/dict/..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "333f062a",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model_name = [\n",
    "    'corr_add_con_imp',\n",
    "    'corr_last_v3', \n",
    "    'corr_c_add_w2v_v1_mish_flg',\n",
    "    'corr_c_add_w2v_v1_flg',\n",
    "    'corr_c_add_84_v1',\n",
    "    'corr_c_add_120_v1',\n",
    "    'corr_w2v_cell_flg',\n",
    "    'corr_best_cell_120',\n",
    "    'corr_cluster_cell',\n",
    "    'corr_w2v_128',\n",
    "    'corr_imp_w2v_128',\n",
    "    'corr_snorm',\n",
    "    'corr_best_128',\n",
    "    'corr_best_64',\n",
    "    'corr_cluster_128',\n",
    "    'corr_cluster_64',\n",
    "    'corr_svd_128',\n",
    "    'corr_svd_64',\n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46f839e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cite_mlp_corr_add_con_imp_flg_donor_val_50',\n",
       " 'cite_mlp_corr_last_v3_flg_donor_val_55',\n",
       " 'cite_mlp_corr_c_add_w2v_v1_mish_flg_donor_val_66',\n",
       " 'cite_mlp_corr_c_add_w2v_v1_flg_donor_val_66',\n",
       " 'cite_mlp_corr_c_add_84_v1_flg_donor_val_47',\n",
       " 'cite_mlp_corr_c_add_120_v1_flg_donor_val_63',\n",
       " 'cite_mlp_corr_w2v_cell_flg_donor_val_51',\n",
       " 'cite_mlp_corr_best_cell_120_flg_donor_val_51',\n",
       " 'cite_mlp_corr_cluster_cell_flg_donor_val_64',\n",
       " 'cite_mlp_corr_w2v_128_flg_donor_val_42',\n",
       " 'cite_mlp_corr_imp_w2v_128_flg_donor_val_38',\n",
       " 'cite_mlp_corr_snorm_flg_donor_val_39',\n",
       " 'cite_mlp_corr_best_128_flg_donor_val_45',\n",
       " 'cite_mlp_corr_best_64_flg_donor_val_50',\n",
       " 'cite_mlp_corr_cluster_128_flg_donor_val_51',\n",
       " 'cite_mlp_corr_cluster_64_flg_donor_val_57',\n",
       " 'cite_mlp_corr_svd_128_flg_donor_val_30',\n",
       " 'cite_mlp_corr_svd_64_flg_donor_val_38']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name_list = []\n",
    "\n",
    "for i in mlp_model_name:\n",
    "    for num, j in enumerate(os.listdir(cite_mlp_path)):\n",
    "        if i in j:\n",
    "            model_name_list.append(j)\n",
    "\n",
    "len(model_name_list)\n",
    "model_name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "16874655",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = [1, 0.3, 1, 1, 1, 1, 1, 1, 1, 0.8, 0.8, 0.8, 0.8, 0.5, 0.5, 0.5, 1, 1, 2, 2]\n",
    "weight_sum = np.array(weight).sum()\n",
    "weight_sum\n",
    "\n",
    "model_feat_dict = {model_name_list[0]:['X_test_add_con_imp.pickle', 1],\n",
    "                   model_name_list[1]:['X_test_last_v3.pickle', 0.3],\n",
    "                   model_name_list[2]:['X_test_c_add_w2v_v1.pickle', 1],\n",
    "                   model_name_list[3]:['X_test_c_add_w2v_v1.pickle', 1],\n",
    "                   model_name_list[4]:['X_test_c_add_84_v1.pickle', 1],\n",
    "                   model_name_list[5]:['X_test_c_add_v1.pickle', 1],\n",
    "                   \n",
    "                   model_name_list[6]:['X_test_feature_w2v_cell.pickle', 1],\n",
    "                   model_name_list[7]:['X_test_best_cell_128_120.pickle', 1],\n",
    "                   model_name_list[8]:['X_test_cluster_cell_128.pickle', 1],\n",
    "                   \n",
    "                   model_name_list[9]:['X_test_feature_w2v.pickle', 0.8],\n",
    "                   model_name_list[10]:['X_test_feature_imp_w2v.pickle',0.8],\n",
    "                   model_name_list[11]:['X_test_feature_snorm.pickle', 0.8],\n",
    "                   model_name_list[12]:['X_test_best_128.pickle', 0.8],\n",
    "                   model_name_list[13]:['X_test_best_64.pickle', 0.5],\n",
    "                   model_name_list[14]:['X_test_cluster_128.pickle', 0.5],\n",
    "                   model_name_list[15]:['X_test_cluster_64.pickle', 0.5],\n",
    "                   model_name_list[16]:['X_test_svd_128.pickle', 1],\n",
    "                   model_name_list[17]:['X_test_svd_64.pickle', 1],\n",
    "                   \n",
    "                   'best_128':['X_test_best_128.pickle', 2],\n",
    "                   'best_64':['X_test_best_64.pickle', 2],\n",
    "                  }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e7f5db4",
   "metadata": {},
   "source": [
    "### cite model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "08f39770",
   "metadata": {},
   "outputs": [],
   "source": [
    "def std(x):\n",
    "    x = np.array(x)\n",
    "    return (x - x.mean(1).reshape(-1, 1)) / x.std(1).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "489b389c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CiteDataset_test(Dataset):\n",
    "    \n",
    "    def __init__(self, feature):\n",
    "        self.feature = feature\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.feature)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "                \n",
    "        d = {\n",
    "            \"X\": self.feature[index]\n",
    "        }\n",
    "        return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c88e6ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CiteModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, feature_num):\n",
    "        super(CiteModel, self).__init__()\n",
    "        \n",
    "        self.layer_seq_256 = nn.Sequential(nn.Linear(feature_num, 256),\n",
    "                                           nn.Linear(256, 128),\n",
    "                                       nn.LayerNorm(128),\n",
    "                                       nn.ReLU(),\n",
    "                                      )\n",
    "        self.layer_seq_64 = nn.Sequential(nn.Linear(128, 64),\n",
    "                                       nn.Linear(64, 32),\n",
    "                                       nn.LayerNorm(32),\n",
    "                                       nn.ReLU(),\n",
    "                                      )\n",
    "        self.layer_seq_8 = nn.Sequential(nn.Linear(32, 16),\n",
    "                                         nn.Linear(16, 8),\n",
    "                                       nn.LayerNorm(8),\n",
    "                                       nn.ReLU(),\n",
    "                                      )\n",
    "        \n",
    "        self.head = nn.Linear(128 + 32 + 8, 140)\n",
    "                   \n",
    "    def forward(self, X, y=None):\n",
    "        \n",
    "        from_numpy = False\n",
    "        \n",
    "      ##\n",
    "        if isinstance(X, np.ndarray):\n",
    "            X = torch.from_numpy(X)\n",
    "            from_numpy = True\n",
    "        X = X.to(device)  # Move the input to the appropriate device if necessary\n",
    "        ##\n",
    "        X_256 = self.layer_seq_256(X)\n",
    "        X_64 = self.layer_seq_64(X_256)\n",
    "        X_8 = self.layer_seq_8(X_64)\n",
    "        \n",
    "        X = torch.cat([X_256, X_64, X_8], axis = 1)\n",
    "        out = self.head(X)\n",
    "        \n",
    "        if from_numpy:\n",
    "            out = out.cpu().detach().numpy()\n",
    "            \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58f4c788",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CiteModel_mish(nn.Module):\n",
    "    \n",
    "    def __init__(self, feature_num):\n",
    "        super(CiteModel_mish, self).__init__()\n",
    "        \n",
    "        self.layer_seq_256 = nn.Sequential(nn.Linear(feature_num, 256),\n",
    "                                           nn.Linear(256, 128),\n",
    "                                       nn.LayerNorm(128),\n",
    "                                       nn.Mish(),\n",
    "                                      )\n",
    "        self.layer_seq_64 = nn.Sequential(nn.Linear(128, 64),\n",
    "                                       nn.Linear(64, 32),\n",
    "                                       nn.LayerNorm(32),\n",
    "                                       nn.Mish(),\n",
    "                                      )\n",
    "        self.layer_seq_8 = nn.Sequential(nn.Linear(32, 16),\n",
    "                                         nn.Linear(16, 8),\n",
    "                                       nn.LayerNorm(8),\n",
    "                                       nn.Mish(),\n",
    "                                      )\n",
    "        \n",
    "        self.head = nn.Linear(128 + 32 + 8, 140)\n",
    "                   \n",
    "    def forward(self, X, y=None):\n",
    "    \n",
    "        X_256 = self.layer_seq_256(X)\n",
    "        X_64 = self.layer_seq_64(X_256)\n",
    "        X_8 = self.layer_seq_8(X_64)\n",
    "        \n",
    "        X = torch.cat([X_256, X_64, X_8], axis = 1)\n",
    "        out = self.head(X)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5add5dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(model, loader):\n",
    "    \n",
    "    model.eval()\n",
    "    predicts=[]\n",
    "\n",
    "    for d in tqdm(loader):\n",
    "        with torch.no_grad():\n",
    "            X = d['X'].to(device)\n",
    "            logits = model(X)\n",
    "            predicts.append(logits.detach().cpu().numpy())\n",
    "            \n",
    "    return np.concatenate(predicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad260fa2",
   "metadata": {},
   "source": [
    "### pred for model #16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ffab957f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only need model, not whole prediction\n",
    "\n",
    "# model #16: cite_mlp_corr_svd_128_flg_donor_val_30\n",
    "\n",
    "model_name = 'cite_mlp_corr_svd_128_flg_donor_val_30'\n",
    "        \n",
    "test_file = model_feat_dict[model_name][0]\n",
    "X_test = pd.read_pickle(cite_feature_path  + test_file)   # do we actually need this? Not for model but for feature_dims (212 in model #16 cases)\n",
    "X_test = np.array(X_test)\n",
    "feature_dims = X_test.shape[1]\n",
    "\n",
    "# test_ds = CiteDataset_test(X_test)\n",
    "# test_dataloader = DataLoader(test_ds, batch_size=128, pin_memory=True, \n",
    "#                               shuffle=False, drop_last=False, num_workers=4)\n",
    "\n",
    "if 'mish' in i:\n",
    "    model = CiteModel_mish(feature_dims)\n",
    "else:\n",
    "    model = CiteModel(feature_dims)\n",
    "    \n",
    "model = model.to(device)\n",
    "model.load_state_dict(torch.load(f'{cite_mlp_path}/{model_name}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b2c4fde",
   "metadata": {},
   "source": [
    "### prepare data for SHAP plot \n",
    "### => shap.KernelExplainer, explainer.shap_values, shap.summary_plot(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa8d2a7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (70988, 212)\n",
      "X_test:  (48203, 212)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 1000 background data samples could cause slower run times. Consider using shap.sample(data, K) or shap.kmeans(data, K) to summarize the background as K samples.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<shap.explainers._kernel.Kernel at 0x7f1b03d1d550>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X_train for model #16: 'X_svd_128.pickle'\n",
    "X_train = pd.read_pickle(cite_feature_path  + 'X_svd_128.pickle')\n",
    "X_train = np.array(X_train)\n",
    "print('X_train: ', X_train.shape)\n",
    "print('X_test: ', X_test.shape)\n",
    "\n",
    "explainer = shap.KernelExplainer(model, shap.sample(X_train, 1000))\n",
    "explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "77705744",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_shap = ad.read_h5ad('X_test_shap_16_50_samples.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "85137e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xtest = X_test_shap.to_df()#.drop(['cell_id', 'cell_type'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "284cab7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features: genes and svd -> omnipath: genes\n",
    "# model: mostly relying on genes or svd? -> later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18988d9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "031b24414f48415c854b27aead3aa669",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/350 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# don't need to run again: np.load('shap_values.npy', allow_pickle=True)\n",
    "%timeit\n",
    "shap_values = explainer.shap_values(X_test_shap.to_df(), nsamples=300)  #500? \n",
    "print(len(shap_values)) # -> 140 genes\n",
    "print(len(shap_values[0])) # -> number of samples in xtest\n",
    "print(shap_values[0].shape)\n",
    "\n",
    "# TODO rename files once double checked that everything works after restructuring\n",
    "np.save('shap_values_16_50_samples_restructured.npy', np.array(shap_values, dtype=object), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94460766",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305c4a3f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e98c6001",
   "metadata": {},
   "source": [
    "### pred for model #17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687427b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO all below: for 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90a9c401",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# only need model, not whole prediction\n",
    "\n",
    "# model #16: cite_mlp_corr_svd_64_flg_donor_val_38\n",
    "\n",
    "model_name = 'cite_mlp_corr_svd_64_flg_donor_val_38'\n",
    "        \n",
    "test_file = model_feat_dict[model_name][0]\n",
    "X_test = pd.read_pickle(cite_feature_path  + test_file)   # do we actually need this? Not for model but for feature_dims (148 in model #17 cases)\n",
    "X_test = np.array(X_test)\n",
    "feature_dims = X_test.shape[1]\n",
    "\n",
    "# test_ds = CiteDataset_test(X_test)\n",
    "# test_dataloader = DataLoader(test_ds, batch_size=128, pin_memory=True, \n",
    "#                               shuffle=False, drop_last=False, num_workers=4)\n",
    "\n",
    "if 'mish' in i:\n",
    "    model17 = CiteModel_mish(feature_dims)\n",
    "else:\n",
    "    model17 = CiteModel(feature_dims)\n",
    "    \n",
    "model17 = model17.to(device)\n",
    "model17.load_state_dict(torch.load(f'{cite_mlp_path}/{model_name}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4931c05",
   "metadata": {},
   "source": [
    "### prepare data for SHAP plot \n",
    "### => shap.KernelExplainer, explainer.shap_values, shap.summary_plot(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ecd5ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train for model #16: 'X_svd_128.pickle'\n",
    "X_train = pd.read_pickle(cite_feature_path  + 'X_svd_64.pickle')  # TODO check\n",
    "X_train = np.array(X_train)\n",
    "print('X_train: ', X_train.shape)\n",
    "print('X_test: ', X_test.shape)\n",
    "\n",
    "explainer = shap.KernelExplainer(model17, shap.sample(X_train, 1000))\n",
    "explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f66cb1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_shap = ad.read_h5ad('X_test_shap_16_50_samples.h5ad')   # TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bfb0519",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "031b24414f48415c854b27aead3aa669",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/350 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# don't need to run again: np.load('shap_values.npy', allow_pickle=True)\n",
    "%timeit\n",
    "shap_values = explainer.shap_values(X_test_shap.to_df(), nsamples=300)  #500? \n",
    "print(len(shap_values)) # -> 140 genes\n",
    "print(len(shap_values[0])) # -> number of samples in xtest\n",
    "print(shap_values[0].shape)\n",
    "\n",
    "# TODO rename files once double checked that everything works after restructuring\n",
    "np.save('shap_values_17_50_samples_restructured.npy', np.array(shap_values, dtype=object), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8d37bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
