{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f56a6fbe",
   "metadata": {},
   "source": [
    "- load model #16\n",
    "- explainer = shap.KernelExplainer(model, X_train)\n",
    "- get shap_values = explainer.shap_values(X_test_shap)\n",
    "- save shap_values_16_n_samples.npy\\\n",
    "=> shap values for 212 features! 128 svd components + 84 handselected genes\n",
    "- same steps for model #17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d7d75ff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture output\n",
    "!pip install --upgrade pip\n",
    "!pip install --upgrade pandas\n",
    "!pip install tables   \n",
    "# necessary for pd.read_hdf()\n",
    "\n",
    "!pip install ipywidgets\n",
    "!pip install --upgrade jupyter\n",
    "!pip install IProgress\n",
    "# !pip install catboost\n",
    "!pip install shap\n",
    "!pip install anndata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec3ee57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import shap\n",
    "\n",
    "import anndata as ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbc8f74a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else 'cpu'\n",
    "# pd.set_option('display.max_rows', 500)\n",
    "# pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15357eb9",
   "metadata": {},
   "source": [
    "## data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "333f276f",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrz_path = '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93zoj/open-problems-multimodal-3rd-solution/'\n",
    "\n",
    "# model_path_for_now = '/dss/dsshome1/02/di93zoj/valentina/open-problems-multimodal-3rd-solution/'\n",
    "\n",
    "raw_path =  lrz_path + 'input/raw/'  # '../../../input/raw/'\n",
    "\n",
    "cite_target_path = lrz_path + 'input/target/cite/'   # '../../../input/target/cite/'\n",
    "cite_feature_path = lrz_path + 'input/features/cite/'   # '../../../input/features/cite/'\n",
    "cite_mlp_path = lrz_path + 'model/cite/mlp/'   # '../../../model/cite/mlp/'   # '../../../model/cite/mlp/'\n",
    "cite_cb_path = lrz_path + 'model/cite/cb/'   # '../../../model/cite/cb/'\n",
    "\n",
    "# multi_target_path = lrz_path + 'input/target/multi/'   # '../../../input/target/multi/'\n",
    "# multi_feature_path = lrz_path + 'input/features/multi/'   # '../../../input/features/multi/'\n",
    "# multi_mlp_path = lrz_path + 'model/multi/mlp/'   # '../../../model/multi/mlp/'\n",
    "# multi_cb_path = lrz_path + 'model/multi/cb/'   # '../../../model/multi/cb/'\n",
    "\n",
    "index_path = lrz_path + 'input/preprocess/cite/'\n",
    "\n",
    "output_path = lrz_path + 'output/'   # '../../../output/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57fd24d2",
   "metadata": {},
   "source": [
    "## Cite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "24734451",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get model name\n",
    "#mlp_model_path = os.listdir(cite_mlp_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f28a2f4c",
   "metadata": {},
   "source": [
    "markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6aedb5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check model names and lists/dict/..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "478c31fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model_name = [\n",
    "    'corr_add_con_imp',\n",
    "    'corr_last_v3', \n",
    "    'corr_c_add_w2v_v1_mish_flg',\n",
    "    'corr_c_add_w2v_v1_flg',\n",
    "    'corr_c_add_84_v1',\n",
    "    'corr_c_add_120_v1',\n",
    "    'corr_w2v_cell_flg',\n",
    "    'corr_best_cell_120',\n",
    "    'corr_cluster_cell',\n",
    "    'corr_w2v_128',\n",
    "    'corr_imp_w2v_128',\n",
    "    'corr_snorm',\n",
    "    'corr_best_128',\n",
    "    'corr_best_64',\n",
    "    'corr_cluster_128',\n",
    "    'corr_cluster_64',\n",
    "    'corr_svd_128',\n",
    "    'corr_svd_64',\n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8b879f96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cite_mlp_corr_add_con_imp_flg_donor_val_50',\n",
       " 'cite_mlp_corr_last_v3_flg_donor_val_55',\n",
       " 'cite_mlp_corr_c_add_w2v_v1_mish_flg_donor_val_66',\n",
       " 'cite_mlp_corr_c_add_w2v_v1_flg_donor_val_66',\n",
       " 'cite_mlp_corr_c_add_84_v1_flg_donor_val_47',\n",
       " 'cite_mlp_corr_c_add_120_v1_flg_donor_val_63',\n",
       " 'cite_mlp_corr_w2v_cell_flg_donor_val_51',\n",
       " 'cite_mlp_corr_best_cell_120_flg_donor_val_51',\n",
       " 'cite_mlp_corr_cluster_cell_flg_donor_val_64',\n",
       " 'cite_mlp_corr_w2v_128_flg_donor_val_42',\n",
       " 'cite_mlp_corr_imp_w2v_128_flg_donor_val_38',\n",
       " 'cite_mlp_corr_snorm_flg_donor_val_39',\n",
       " 'cite_mlp_corr_best_128_flg_donor_val_45',\n",
       " 'cite_mlp_corr_best_64_flg_donor_val_50',\n",
       " 'cite_mlp_corr_cluster_128_flg_donor_val_51',\n",
       " 'cite_mlp_corr_cluster_64_flg_donor_val_57',\n",
       " 'cite_mlp_corr_svd_128_flg_donor_val_30',\n",
       " 'cite_mlp_corr_svd_64_flg_donor_val_38']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name_list = []\n",
    "\n",
    "for i in mlp_model_name:\n",
    "    for num, j in enumerate(os.listdir(cite_mlp_path)):\n",
    "        if i in j:\n",
    "            model_name_list.append(j)\n",
    "\n",
    "len(model_name_list)\n",
    "model_name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4714e30",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = [1, 0.3, 1, 1, 1, 1, 1, 1, 1, 0.8, 0.8, 0.8, 0.8, 0.5, 0.5, 0.5, 1, 1, 2, 2]\n",
    "weight_sum = np.array(weight).sum()\n",
    "weight_sum\n",
    "\n",
    "model_feat_dict = {model_name_list[0]:['X_test_add_con_imp.pickle', 1],\n",
    "                   model_name_list[1]:['X_test_last_v3.pickle', 0.3],\n",
    "                   model_name_list[2]:['X_test_c_add_w2v_v1.pickle', 1],\n",
    "                   model_name_list[3]:['X_test_c_add_w2v_v1.pickle', 1],\n",
    "                   model_name_list[4]:['X_test_c_add_84_v1.pickle', 1],\n",
    "                   model_name_list[5]:['X_test_c_add_v1.pickle', 1],\n",
    "                   \n",
    "                   model_name_list[6]:['X_test_feature_w2v_cell.pickle', 1],\n",
    "                   model_name_list[7]:['X_test_best_cell_128_120.pickle', 1],\n",
    "                   model_name_list[8]:['X_test_cluster_cell_128.pickle', 1],\n",
    "                   \n",
    "                   model_name_list[9]:['X_test_feature_w2v.pickle', 0.8],\n",
    "                   model_name_list[10]:['X_test_feature_imp_w2v.pickle',0.8],\n",
    "                   model_name_list[11]:['X_test_feature_snorm.pickle', 0.8],\n",
    "                   model_name_list[12]:['X_test_best_128.pickle', 0.8],\n",
    "                   model_name_list[13]:['X_test_best_64.pickle', 0.5],\n",
    "                   model_name_list[14]:['X_test_cluster_128.pickle', 0.5],\n",
    "                   model_name_list[15]:['X_test_cluster_64.pickle', 0.5],\n",
    "                   model_name_list[16]:['X_test_svd_128.pickle', 1],\n",
    "                   model_name_list[17]:['X_test_svd_64.pickle', 1],\n",
    "                   \n",
    "                   'best_128':['X_test_best_128.pickle', 2],\n",
    "                   'best_64':['X_test_best_64.pickle', 2],\n",
    "                  }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f881de4a",
   "metadata": {},
   "source": [
    "### cite model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d533255",
   "metadata": {},
   "outputs": [],
   "source": [
    "def std(x):\n",
    "    x = np.array(x)\n",
    "    return (x - x.mean(1).reshape(-1, 1)) / x.std(1).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1631fe60",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CiteDataset_test(Dataset):\n",
    "    \n",
    "    def __init__(self, feature):\n",
    "        self.feature = feature\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.feature)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "                \n",
    "        d = {\n",
    "            \"X\": self.feature[index]\n",
    "        }\n",
    "        return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a408ff2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CiteModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, feature_num):\n",
    "        super(CiteModel, self).__init__()\n",
    "        \n",
    "        self.layer_seq_256 = nn.Sequential(nn.Linear(feature_num, 256),\n",
    "                                           nn.Linear(256, 128),\n",
    "                                       nn.LayerNorm(128),\n",
    "                                       nn.ReLU(),\n",
    "                                      )\n",
    "        self.layer_seq_64 = nn.Sequential(nn.Linear(128, 64),\n",
    "                                       nn.Linear(64, 32),\n",
    "                                       nn.LayerNorm(32),\n",
    "                                       nn.ReLU(),\n",
    "                                      )\n",
    "        self.layer_seq_8 = nn.Sequential(nn.Linear(32, 16),\n",
    "                                         nn.Linear(16, 8),\n",
    "                                       nn.LayerNorm(8),\n",
    "                                       nn.ReLU(),\n",
    "                                      )\n",
    "        \n",
    "        self.head = nn.Linear(128 + 32 + 8, 140)\n",
    "                   \n",
    "    def forward(self, X, y=None):\n",
    "        \n",
    "        from_numpy = False\n",
    "        \n",
    "      ##\n",
    "        if isinstance(X, np.ndarray):\n",
    "            X = torch.from_numpy(X)\n",
    "            from_numpy = True\n",
    "        X = X.to(device)  # Move the input to the appropriate device if necessary\n",
    "        ##\n",
    "        X_256 = self.layer_seq_256(X)\n",
    "        X_64 = self.layer_seq_64(X_256)\n",
    "        X_8 = self.layer_seq_8(X_64)\n",
    "        \n",
    "        X = torch.cat([X_256, X_64, X_8], axis = 1)\n",
    "        out = self.head(X)\n",
    "        \n",
    "        if from_numpy:\n",
    "            out = out.cpu().detach().numpy()\n",
    "            \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f8dcb946",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CiteModel_mish(nn.Module):\n",
    "    \n",
    "    def __init__(self, feature_num):\n",
    "        super(CiteModel_mish, self).__init__()\n",
    "        \n",
    "        self.layer_seq_256 = nn.Sequential(nn.Linear(feature_num, 256),\n",
    "                                           nn.Linear(256, 128),\n",
    "                                       nn.LayerNorm(128),\n",
    "                                       nn.Mish(),\n",
    "                                      )\n",
    "        self.layer_seq_64 = nn.Sequential(nn.Linear(128, 64),\n",
    "                                       nn.Linear(64, 32),\n",
    "                                       nn.LayerNorm(32),\n",
    "                                       nn.Mish(),\n",
    "                                      )\n",
    "        self.layer_seq_8 = nn.Sequential(nn.Linear(32, 16),\n",
    "                                         nn.Linear(16, 8),\n",
    "                                       nn.LayerNorm(8),\n",
    "                                       nn.Mish(),\n",
    "                                      )\n",
    "        \n",
    "        self.head = nn.Linear(128 + 32 + 8, 140)\n",
    "                   \n",
    "    def forward(self, X, y=None):\n",
    "    \n",
    "        X_256 = self.layer_seq_256(X)\n",
    "        X_64 = self.layer_seq_64(X_256)\n",
    "        X_8 = self.layer_seq_8(X_64)\n",
    "        \n",
    "        X = torch.cat([X_256, X_64, X_8], axis = 1)\n",
    "        out = self.head(X)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79109417",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(model, loader):\n",
    "    \n",
    "    model.eval()\n",
    "    predicts=[]\n",
    "\n",
    "    for d in tqdm(loader):\n",
    "        with torch.no_grad():\n",
    "            X = d['X'].to(device)\n",
    "            logits = model(X)\n",
    "            predicts.append(logits.detach().cpu().numpy())\n",
    "            \n",
    "    return np.concatenate(predicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e7bfef",
   "metadata": {},
   "source": [
    "### pred for model #16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed8fa473",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only need model, not whole prediction\n",
    "\n",
    "# model #16: cite_mlp_corr_svd_128_flg_donor_val_30\n",
    "\n",
    "model_name = 'cite_mlp_corr_svd_128_flg_donor_val_30'\n",
    "        \n",
    "test_file = model_feat_dict[model_name][0]\n",
    "X_test = pd.read_pickle(cite_feature_path  + test_file)   # do we actually need this? Not for model but for feature_dims (212 in model #16 cases)\n",
    "X_test = np.array(X_test)\n",
    "feature_dims = X_test.shape[1]\n",
    "\n",
    "# test_ds = CiteDataset_test(X_test)\n",
    "# test_dataloader = DataLoader(test_ds, batch_size=128, pin_memory=True, \n",
    "#                               shuffle=False, drop_last=False, num_workers=4)\n",
    "\n",
    "if 'mish' in i:\n",
    "    model16 = CiteModel_mish(feature_dims)\n",
    "else:\n",
    "    model16 = CiteModel(feature_dims)\n",
    "    \n",
    "model16 = model16.to(device)\n",
    "model16.load_state_dict(torch.load(f'{cite_mlp_path}/{model_name}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f4a48a",
   "metadata": {},
   "source": [
    "### prepare data for SHAP plot \n",
    "### => shap.KernelExplainer, explainer.shap_values, shap.summary_plot(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e391ab06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 1000 background data samples could cause slower run times. Consider using shap.sample(data, K) or shap.kmeans(data, K) to summarize the background as K samples.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (70988, 212)\n",
      "X_test:  (48203, 148)\n"
     ]
    }
   ],
   "source": [
    "# X_train for model #16: 'X_svd_128.pickle'\n",
    "X_train = pd.read_pickle(cite_feature_path  + 'X_svd_128.pickle')\n",
    "X_train = np.array(X_train)\n",
    "print('X_train: ', X_train.shape)\n",
    "print('X_test: ', X_test.shape)\n",
    "\n",
    "explainer16 = shap.KernelExplainer(model16, shap.sample(X_train, 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6331c69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_shap = ad.read_h5ad('X_test_shap_16_50_samples.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "706cb638",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xtest = X_test_shap.to_df()#.drop(['cell_id', 'cell_type'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9a2a8104",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features: genes and svd -> omnipath: genes\n",
    "# model: mostly relying on genes or svd? -> later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ed41192b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # don't need to run again: np.load('shap_values.npy', allow_pickle=True)\n",
    "# %timeit\n",
    "# shap_values = explainer16.shap_values(X_test_shap.to_df(), nsamples=300)  #500? \n",
    "# print(len(shap_values)) # -> 140 genes\n",
    "# print(len(shap_values[0])) # -> number of samples in xtest\n",
    "# print(shap_values[0].shape)\n",
    "\n",
    "# # TODO rename files once double checked that everything works after restructuring\n",
    "# np.save('shap_values_16_50_samples_restructured.npy', np.array(shap_values, dtype=object), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b7b167cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.00000000e+00,  1.72301374e-01,  0.00000000e+00, ...,\n",
       "         0.00000000e+00,  9.78120557e-03,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  7.14406430e-02,  1.73186417e-01, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00,  2.76850097e-01, -2.05803679e-02, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       ...,\n",
       "       [ 0.00000000e+00,  1.51683968e-01, -3.23064426e-02, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  0.00000000e+00],\n",
       "       [ 0.00000000e+00, -8.51794008e-02, -1.81796092e-02, ...,\n",
       "         0.00000000e+00,  0.00000000e+00,  2.54393411e-03],\n",
       "       [ 0.00000000e+00,  2.45819411e-01, -2.48508076e-02, ...,\n",
       "        -5.25790953e-05,  0.00000000e+00,  0.00000000e+00]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shap_values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87c645b",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d4177286",
   "metadata": {},
   "source": [
    "### pred for model #17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c2a1de40",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only need model, not whole prediction\n",
    "# model #16: cite_mlp_corr_svd_64_flg_donor_val_38\n",
    "\n",
    "model_name = 'cite_mlp_corr_svd_64_flg_donor_val_38'\n",
    "        \n",
    "test_file = model_feat_dict[model_name][0]\n",
    "X_test = pd.read_pickle(cite_feature_path  + test_file)   # do we actually need this? Not for model but for feature_dims (148 in model #17 cases)\n",
    "X_test = np.array(X_test)\n",
    "feature_dims = X_test.shape[1]\n",
    "\n",
    "# test_ds = CiteDataset_test(X_test)\n",
    "# test_dataloader = DataLoader(test_ds, batch_size=128, pin_memory=True, \n",
    "#                               shuffle=False, drop_last=False, num_workers=4)\n",
    "\n",
    "if 'mish' in i:\n",
    "    model17 = CiteModel_mish(feature_dims)\n",
    "else:\n",
    "    model17 = CiteModel(feature_dims)\n",
    "    \n",
    "model17 = model17.to(device)\n",
    "model17.load_state_dict(torch.load(f'{cite_mlp_path}/{model_name}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20173add",
   "metadata": {},
   "source": [
    "### prepare data for SHAP plot \n",
    "### => shap.KernelExplainer, explainer.shap_values, shap.summary_plot(shap_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "aac4e057",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 1000 background data samples could cause slower run times. Consider using shap.sample(data, K) or shap.kmeans(data, K) to summarize the background as K samples.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (70988, 148)\n",
      "X_test:  (48203, 148)\n"
     ]
    }
   ],
   "source": [
    "# X_train for model #16: 'X_svd_128.pickle'\n",
    "X_train = pd.read_pickle(cite_feature_path  + 'X_svd_64.pickle')  # TODO check\n",
    "X_train = np.array(X_train)\n",
    "print('X_train: ', X_train.shape)\n",
    "print('X_test: ', X_test.shape)\n",
    "\n",
    "explainer17 = shap.KernelExplainer(model17, shap.sample(X_train, 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "08809742",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_shap = ad.read_h5ad('X_test_shap_17_50_samples.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a55cd771",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3f8a51f095b4a5d9990a37bba860edd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/350 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # don't need to run again: np.load('shap_values.npy', allow_pickle=True)\n",
    "# %timeit\n",
    "# shap_values = explainer17.shap_values(X_test_shap.to_df(), nsamples=300)  #500? \n",
    "# print(len(shap_values)) # -> 140 genes\n",
    "# print(len(shap_values[0])) # -> number of samples in xtest\n",
    "# print(shap_values[0].shape)\n",
    "\n",
    "# # TODO rename files once double checked that everything works after restructuring\n",
    "# np.save('shap_values_17_50_samples_restructured.npy', np.array(shap_values, dtype=object), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f060dac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap_values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "975678d5",
   "metadata": {},
   "source": [
    "### same steps for private test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a04da31",
   "metadata": {},
   "source": [
    "steps for model 16: compute shap values on 50 samples per cell type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7b4fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test:  (350, 212)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c38cf08876f432480e9b11fc6c5c866",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/350 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train_p = pd.read_pickle('/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93zoj/kaggle/full_data/20220830_citeseq_rna_count_train.pkl')\n",
    "#X_train_p = np.array(X_train_p)\n",
    "\n",
    "X_test_p = ad.read_h5ad('private_test_input_128_svd_50_samples.h5ad')\n",
    "\n",
    "# print('X_train: ', X_train_p.shape)\n",
    "print('X_test: ', X_test_p.X.shape)\n",
    "\n",
    "## explainer = shap.KernelExplainer(model16, shap.sample(X_train_p, 1000))\n",
    "## explainer  # use same explainer trained above (?)\n",
    "\n",
    "shap_values = explainer16.shap_values(X_test_p.to_df(), nsamples=300)   # using same explainer16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e96fc4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using newly trained explainer:\n",
    "explainer16_p = shap.KernelExplainer(model16, shap.sample(X_train_p, 1000))\n",
    "shap_values_new = explainer16_p.shap_values(X_test_p.to_df(), nsamples=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "098ee574",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43431c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('shap_values_16_50_samples_p.npy', np.array(shap_values, dtype=object), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bd1953",
   "metadata": {},
   "source": [
    "steps for model 17: compute shap values on 50 samples per cell type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39c0f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_p = pd.read_pickle('/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93zoj/kaggle/full_data/20220830_citeseq_rna_count_train.pkl')\n",
    "#X_train_p = np.array(X_train_p)\n",
    "\n",
    "X_test_p = ad.read_h5ad('private_test_input_64_svd_50_samples.h5ad')\n",
    "\n",
    "# print('X_train: ', X_train_p.shape)\n",
    "print('X_test: ', X_test_p.X.shape)\n",
    "\n",
    "## explainer = shap.KernelExplainer(model16, shap.sample(X_train_p, 1000))\n",
    "## explainer  # use same explainer trained above (?)\n",
    "\n",
    "shap_values = explainer17.shap_values(X_test_p.to_df(), nsamples=300)   # using same explainer16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ca4c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using newly trained explainer:\n",
    "explainer17_p = shap.KernelExplainer(model17, shap.sample(X_train_p, 1000))\n",
    "shap_values_new = explainer17_p.shap_values(X_test_p.to_df(), nsamples=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c99392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('shap_values_16_50_samples_p.npy', np.array(shap_values, dtype=object), allow_pickle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
