{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8d84915c",
   "metadata": {},
   "source": [
    "- load model #16\n",
    "- explainer = shap.KernelExplainer(model, X_train)\n",
    "- get shap_values = explainer.shap_values(X_test_shap)\n",
    "- save shap_values_16_n_samples.npy\\\n",
    "=> shap values for 212 features! 128 svd components + 84 handselected genes\n",
    "- same steps for model #17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27881c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture output\n",
    "!pip install --upgrade pip\n",
    "!pip install --upgrade pandas\n",
    "!pip install tables   \n",
    "# necessary for pd.read_hdf()\n",
    "\n",
    "!pip install ipywidgets\n",
    "!pip install --upgrade jupyter\n",
    "!pip install IProgress\n",
    "# !pip install catboost\n",
    "!pip install shap\n",
    "!pip install anndata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "53e3c563",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "import shap\n",
    "\n",
    "import anndata as ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "288fdb88",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else 'cpu'\n",
    "# pd.set_option('display.max_rows', 500)\n",
    "# pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831b8be2",
   "metadata": {},
   "source": [
    "## data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bfb6eebf",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrz_path = '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93zoj/open-problems-multimodal-3rd-solution/'\n",
    "\n",
    "# model_path_for_now = '/dss/dsshome1/02/di93zoj/valentina/open-problems-multimodal-3rd-solution/'\n",
    "\n",
    "raw_path =  lrz_path + 'input/raw/'  # '../../../input/raw/'\n",
    "\n",
    "cite_target_path = lrz_path + 'input/target/cite/'   # '../../../input/target/cite/'\n",
    "cite_feature_path = lrz_path + 'input/features/cite/'   # '../../../input/features/cite/'\n",
    "cite_mlp_path = lrz_path + 'model/cite/mlp/'   # '../../../model/cite/mlp/'   # '../../../model/cite/mlp/'\n",
    "cite_cb_path = lrz_path + 'model/cite/cb/'   # '../../../model/cite/cb/'\n",
    "\n",
    "# multi_target_path = lrz_path + 'input/target/multi/'   # '../../../input/target/multi/'\n",
    "# multi_feature_path = lrz_path + 'input/features/multi/'   # '../../../input/features/multi/'\n",
    "# multi_mlp_path = lrz_path + 'model/multi/mlp/'   # '../../../model/multi/mlp/'\n",
    "# multi_cb_path = lrz_path + 'model/multi/cb/'   # '../../../model/multi/cb/'\n",
    "\n",
    "index_path = lrz_path + 'input/preprocess/cite/'\n",
    "\n",
    "output_path = lrz_path + 'output/'   # '../../../output/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74737936",
   "metadata": {},
   "source": [
    "## Cite  (code from codebase, same steps as in run_model.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8790cd8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model_name = [\n",
    "    'corr_add_con_imp',\n",
    "    'corr_last_v3', \n",
    "    'corr_c_add_w2v_v1_mish_flg',\n",
    "    'corr_c_add_w2v_v1_flg',\n",
    "    'corr_c_add_84_v1',\n",
    "    'corr_c_add_120_v1',\n",
    "    'corr_w2v_cell_flg',\n",
    "    'corr_best_cell_120',\n",
    "    'corr_cluster_cell',\n",
    "    'corr_w2v_128',\n",
    "    'corr_imp_w2v_128',\n",
    "    'corr_snorm',\n",
    "    'corr_best_128',\n",
    "    'corr_best_64',\n",
    "    'corr_cluster_128',\n",
    "    'corr_cluster_64',\n",
    "    'corr_svd_128',\n",
    "    'corr_svd_64',\n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4afe3860",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cite_mlp_corr_add_con_imp_flg_donor_val_50',\n",
       " 'cite_mlp_corr_last_v3_flg_donor_val_55',\n",
       " 'cite_mlp_corr_c_add_w2v_v1_mish_flg_donor_val_66',\n",
       " 'cite_mlp_corr_c_add_w2v_v1_flg_donor_val_66',\n",
       " 'cite_mlp_corr_c_add_84_v1_flg_donor_val_47',\n",
       " 'cite_mlp_corr_c_add_120_v1_flg_donor_val_63',\n",
       " 'cite_mlp_corr_w2v_cell_flg_donor_val_51',\n",
       " 'cite_mlp_corr_best_cell_120_flg_donor_val_51',\n",
       " 'cite_mlp_corr_cluster_cell_flg_donor_val_64',\n",
       " 'cite_mlp_corr_w2v_128_flg_donor_val_42',\n",
       " 'cite_mlp_corr_imp_w2v_128_flg_donor_val_38',\n",
       " 'cite_mlp_corr_snorm_flg_donor_val_39',\n",
       " 'cite_mlp_corr_best_128_flg_donor_val_45',\n",
       " 'cite_mlp_corr_best_64_flg_donor_val_50',\n",
       " 'cite_mlp_corr_cluster_128_flg_donor_val_51',\n",
       " 'cite_mlp_corr_cluster_64_flg_donor_val_57',\n",
       " 'cite_mlp_corr_svd_128_flg_donor_val_30',\n",
       " 'cite_mlp_corr_svd_64_flg_donor_val_38']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name_list = []\n",
    "\n",
    "for i in mlp_model_name:\n",
    "    for num, j in enumerate(os.listdir(cite_mlp_path)):\n",
    "        if i in j:\n",
    "            model_name_list.append(j)\n",
    "\n",
    "len(model_name_list)\n",
    "model_name_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bb4ea80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = [1, 0.3, 1, 1, 1, 1, 1, 1, 1, 0.8, 0.8, 0.8, 0.8, 0.5, 0.5, 0.5, 1, 1, 2, 2]\n",
    "weight_sum = np.array(weight).sum()\n",
    "weight_sum\n",
    "\n",
    "model_feat_dict = {model_name_list[0]:['X_test_add_con_imp.pickle', 1],\n",
    "                   model_name_list[1]:['X_test_last_v3.pickle', 0.3],\n",
    "                   model_name_list[2]:['X_test_c_add_w2v_v1.pickle', 1],\n",
    "                   model_name_list[3]:['X_test_c_add_w2v_v1.pickle', 1],\n",
    "                   model_name_list[4]:['X_test_c_add_84_v1.pickle', 1],\n",
    "                   model_name_list[5]:['X_test_c_add_v1.pickle', 1],\n",
    "                   \n",
    "                   model_name_list[6]:['X_test_feature_w2v_cell.pickle', 1],\n",
    "                   model_name_list[7]:['X_test_best_cell_128_120.pickle', 1],\n",
    "                   model_name_list[8]:['X_test_cluster_cell_128.pickle', 1],\n",
    "                   \n",
    "                   model_name_list[9]:['X_test_feature_w2v.pickle', 0.8],\n",
    "                   model_name_list[10]:['X_test_feature_imp_w2v.pickle',0.8],\n",
    "                   model_name_list[11]:['X_test_feature_snorm.pickle', 0.8],\n",
    "                   model_name_list[12]:['X_test_best_128.pickle', 0.8],\n",
    "                   model_name_list[13]:['X_test_best_64.pickle', 0.5],\n",
    "                   model_name_list[14]:['X_test_cluster_128.pickle', 0.5],\n",
    "                   model_name_list[15]:['X_test_cluster_64.pickle', 0.5],\n",
    "                   model_name_list[16]:['X_test_svd_128.pickle', 1],\n",
    "                   model_name_list[17]:['X_test_svd_64.pickle', 1],\n",
    "                   \n",
    "                   'best_128':['X_test_best_128.pickle', 2],\n",
    "                   'best_64':['X_test_best_64.pickle', 2],\n",
    "                  }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d329c3a",
   "metadata": {},
   "source": [
    "### cite model (from codebase)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe1f4a3",
   "metadata": {},
   "source": [
    "Only need to load the model, not run the predictions as they are in run_model.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd968308",
   "metadata": {},
   "outputs": [],
   "source": [
    "def std(x):\n",
    "    x = np.array(x)\n",
    "    return (x - x.mean(1).reshape(-1, 1)) / x.std(1).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a9b547a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CiteDataset_test(Dataset):\n",
    "    \n",
    "    def __init__(self, feature):\n",
    "        self.feature = feature\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.feature)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "                \n",
    "        d = {\n",
    "            \"X\": self.feature[index]\n",
    "        }\n",
    "        return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "313a5117",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CiteModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, feature_num):\n",
    "        super(CiteModel, self).__init__()\n",
    "        \n",
    "        self.layer_seq_256 = nn.Sequential(nn.Linear(feature_num, 256),\n",
    "                                           nn.Linear(256, 128),\n",
    "                                       nn.LayerNorm(128),\n",
    "                                       nn.ReLU(),\n",
    "                                      )\n",
    "        self.layer_seq_64 = nn.Sequential(nn.Linear(128, 64),\n",
    "                                       nn.Linear(64, 32),\n",
    "                                       nn.LayerNorm(32),\n",
    "                                       nn.ReLU(),\n",
    "                                      )\n",
    "        self.layer_seq_8 = nn.Sequential(nn.Linear(32, 16),\n",
    "                                         nn.Linear(16, 8),\n",
    "                                       nn.LayerNorm(8),\n",
    "                                       nn.ReLU(),\n",
    "                                      )\n",
    "        \n",
    "        self.head = nn.Linear(128 + 32 + 8, 140)\n",
    "                   \n",
    "    def forward(self, X, y=None):\n",
    "        \n",
    "        from_numpy = False\n",
    "        \n",
    "      ##\n",
    "        if isinstance(X, np.ndarray):\n",
    "            X = torch.from_numpy(X)\n",
    "            from_numpy = True\n",
    "        X = X.to(device)  # Move the input to the appropriate device if necessary\n",
    "        ##\n",
    "        X_256 = self.layer_seq_256(X)\n",
    "        X_64 = self.layer_seq_64(X_256)\n",
    "        X_8 = self.layer_seq_8(X_64)\n",
    "        \n",
    "        X = torch.cat([X_256, X_64, X_8], axis = 1)\n",
    "        out = self.head(X)\n",
    "        \n",
    "        if from_numpy:\n",
    "            out = out.cpu().detach().numpy()\n",
    "            \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1fa5fdf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CiteModel_mish(nn.Module):\n",
    "    \n",
    "    def __init__(self, feature_num):\n",
    "        super(CiteModel_mish, self).__init__()\n",
    "        \n",
    "        self.layer_seq_256 = nn.Sequential(nn.Linear(feature_num, 256),\n",
    "                                           nn.Linear(256, 128),\n",
    "                                       nn.LayerNorm(128),\n",
    "                                       nn.Mish(),\n",
    "                                      )\n",
    "        self.layer_seq_64 = nn.Sequential(nn.Linear(128, 64),\n",
    "                                       nn.Linear(64, 32),\n",
    "                                       nn.LayerNorm(32),\n",
    "                                       nn.Mish(),\n",
    "                                      )\n",
    "        self.layer_seq_8 = nn.Sequential(nn.Linear(32, 16),\n",
    "                                         nn.Linear(16, 8),\n",
    "                                       nn.LayerNorm(8),\n",
    "                                       nn.Mish(),\n",
    "                                      )\n",
    "        \n",
    "        self.head = nn.Linear(128 + 32 + 8, 140)\n",
    "                   \n",
    "    def forward(self, X, y=None):\n",
    "    \n",
    "        X_256 = self.layer_seq_256(X)\n",
    "        X_64 = self.layer_seq_64(X_256)\n",
    "        X_8 = self.layer_seq_8(X_64)\n",
    "        \n",
    "        X = torch.cat([X_256, X_64, X_8], axis = 1)\n",
    "        out = self.head(X)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7432fff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(model, loader):\n",
    "    \n",
    "    model.eval()\n",
    "    predicts=[]\n",
    "\n",
    "    for d in tqdm(loader):\n",
    "        with torch.no_grad():\n",
    "            X = d['X'].to(device)\n",
    "            logits = model(X)\n",
    "            predicts.append(logits.detach().cpu().numpy())\n",
    "            \n",
    "    return np.concatenate(predicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8142d83d",
   "metadata": {},
   "source": [
    "### model #16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "18cbb642",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only need model, not whole prediction\n",
    "\n",
    "# model #16: cite_mlp_corr_svd_128_flg_donor_val_30\n",
    "\n",
    "model_name = 'cite_mlp_corr_svd_128_flg_donor_val_30'\n",
    "        \n",
    "test_file = model_feat_dict[model_name][0]\n",
    "X_test = pd.read_pickle(cite_feature_path  + test_file)\n",
    "X_test = np.array(X_test)\n",
    "feature_dims = X_test.shape[1]\n",
    "\n",
    "if 'mish' in i:\n",
    "    model16 = CiteModel_mish(feature_dims)\n",
    "else:\n",
    "    model16 = CiteModel(feature_dims)\n",
    "    \n",
    "model16 = model16.to(device)\n",
    "model16.load_state_dict(torch.load(f'{cite_mlp_path}/{model_name}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8932b62d",
   "metadata": {},
   "source": [
    "### prepare data to get shap values used for plots in plotting.ipynb \n",
    "### => shap.KernelExplainer, explainer.shap_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2fbec080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (70988, 212)\n",
      "X_test:  (48203, 212)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 1000 background data samples could cause slower run times. Consider using shap.sample(data, K) or shap.kmeans(data, K) to summarize the background as K samples.\n"
     ]
    }
   ],
   "source": [
    "# X_train for model #16: 'X_svd_128.pickle'\n",
    "X_train = pd.read_pickle(cite_feature_path  + 'X_svd_128.pickle')\n",
    "X_train = np.array(X_train)\n",
    "print('X_train: ', X_train.shape)\n",
    "print('X_test: ', X_test.shape)\n",
    "\n",
    "explainer16 = shap.KernelExplainer(model16, shap.sample(X_train, 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f7c4e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_shap = ad.read_h5ad('X_test_shap_16_50_samples.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a1b568a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# xtest = X_test_shap.to_df()#.drop(['cell_id', 'cell_type'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6248a940",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features: genes and svd -> omnipath: genes\n",
    "# model: mostly relying on genes or svd? -> later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "87f61b3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # don't need to run again: np.load('shap_values.npy', allow_pickle=True)\n",
    "# %timeit\n",
    "# shap_values = explainer16.shap_values(X_test_shap.to_df(), nsamples=300)  #500? \n",
    "# print(len(shap_values)) # -> 140 genes\n",
    "# print(len(shap_values[0])) # -> number of samples in xtest\n",
    "# print(shap_values[0].shape)\n",
    "\n",
    "# # TODO rename files once double checked that everything works after restructuring\n",
    "# np.save('shap_values_16_50_samples_restructured.npy', np.array(shap_values, dtype=object), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "74964be7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'shap_values' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mshap_values\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'shap_values' is not defined"
     ]
    }
   ],
   "source": [
    "# shap_values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216b26b2",
   "metadata": {},
   "source": [
    "### model #17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8db15987",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only need model, not whole prediction\n",
    "# model #16: cite_mlp_corr_svd_64_flg_donor_val_38\n",
    "\n",
    "model_name = 'cite_mlp_corr_svd_64_flg_donor_val_38'\n",
    "        \n",
    "test_file = model_feat_dict[model_name][0]\n",
    "X_test = pd.read_pickle(cite_feature_path  + test_file)\n",
    "X_test = np.array(X_test)\n",
    "feature_dims = X_test.shape[1]\n",
    "\n",
    "if 'mish' in i:\n",
    "    model17 = CiteModel_mish(feature_dims)\n",
    "else:\n",
    "    model17 = CiteModel(feature_dims)\n",
    "    \n",
    "model17 = model17.to(device)\n",
    "model17.load_state_dict(torch.load(f'{cite_mlp_path}/{model_name}'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78fa5d07",
   "metadata": {},
   "source": [
    "### prepare data to get shap values used for plots in plotting.ipynb \n",
    "### => shap.KernelExplainer, explainer.shap_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3c547042",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 1000 background data samples could cause slower run times. Consider using shap.sample(data, K) or shap.kmeans(data, K) to summarize the background as K samples.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train:  (70988, 148)\n",
      "X_test:  (48203, 148)\n"
     ]
    }
   ],
   "source": [
    "# X_train for model #17: 'X_svd_64.pickle'\n",
    "X_train = pd.read_pickle(cite_feature_path  + 'X_svd_64.pickle')\n",
    "X_train = np.array(X_train)\n",
    "print('X_train: ', X_train.shape)\n",
    "print('X_test: ', X_test.shape)\n",
    "\n",
    "explainer17 = shap.KernelExplainer(model17, shap.sample(X_train, 1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e2a5352f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_shap = ad.read_h5ad('X_test_shap_17_50_samples.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0374860e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # don't need to run again: np.load('shap_values.npy', allow_pickle=True)\n",
    "# %timeit\n",
    "# shap_values = explainer17.shap_values(X_test_shap.to_df(), nsamples=300)  #500? \n",
    "# print(len(shap_values)) # -> 140 genes\n",
    "# print(len(shap_values[0])) # -> number of samples in xtest\n",
    "# print(shap_values[0].shape)\n",
    "\n",
    "# # TODO rename files once double checked that everything works after restructuring\n",
    "# np.save('shap_values_17_50_samples_restructured.npy', np.array(shap_values, dtype=object), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a1dc028f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shap_values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa27c7fc",
   "metadata": {},
   "source": [
    "### same steps for private test data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c92b56e",
   "metadata": {},
   "source": [
    "steps for model 16: compute shap values on 50 samples per cell type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3b18fbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_test:  (350, 212)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37bf28887dfd42a3b785f590641e24cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/350 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train_p = pd.read_pickle('/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93zoj/kaggle/full_data/20220830_citeseq_rna_count_train.pkl')\n",
    "#X_train_p = np.array(X_train_p)\n",
    "\n",
    "X_test_p = ad.read_h5ad('private_test_input_128_svd_50_samples.h5ad')\n",
    "\n",
    "# print('X_train: ', X_train_p.shape)\n",
    "print('X_test: ', X_test_p.X.shape)\n",
    "\n",
    "## explainer = shap.KernelExplainer(model16, shap.sample(X_train_p, 1000))\n",
    "## explainer  # use same explainer trained above (?)\n",
    "\n",
    "shap_values_16_p = explainer16.shap_values(X_test_p.to_df(), nsamples=300)   # using same explainer16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e6a6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('shap_values_16_50_samples_p.npy', np.array(shap_values_16_p, dtype=object), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65d9e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using newly trained explainer:\n",
    "explainer16_p = shap.KernelExplainer(model16, shap.sample(X_train_p, 1000))\n",
    "shap_values16_p_new = explainer16_p.shap_values(X_test_p.to_df(), nsamples=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbad9a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('shap_values_16_50_samples_p_new.npy', np.array(shap_values_16_p_new, dtype=object), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73e182e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('shap_values_16_50_samples_p.npy', np.array(shap_values, dtype=object), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d9beaca",
   "metadata": {},
   "source": [
    "steps for model 17: compute shap values on 50 samples per cell type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f799ed63",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_p = pd.read_pickle('/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93zoj/kaggle/full_data/20220830_citeseq_rna_count_train.pkl')\n",
    "#X_train_p = np.array(X_train_p)\n",
    "\n",
    "X_test_p = ad.read_h5ad('private_test_input_64_svd_50_samples.h5ad')\n",
    "\n",
    "# print('X_train: ', X_train_p.shape)\n",
    "print('X_test: ', X_test_p.X.shape)\n",
    "\n",
    "## explainer = shap.KernelExplainer(model16, shap.sample(X_train_p, 1000))\n",
    "## explainer  # use same explainer trained above (?)\n",
    "\n",
    "shap_values_17_p = explainer17.shap_values(X_test_p.to_df(), nsamples=300)   # using same explainer16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6e6c093",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('shap_values_17_50_samples_p.npy', np.array(shap_values_17_p, dtype=object), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5b2fc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using newly trained explainer:\n",
    "explainer17_p = shap.KernelExplainer(model17, shap.sample(X_train_p, 1000))\n",
    "shap_values_17_p_new = explainer17_p.shap_values(X_test_p.to_df(), nsamples=300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d164cd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('shap_values_17_50_samples_p_new.npy', np.array(shap_values_17_p-new, dtype=object), allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85c1d3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.save('shap_values_16_50_samples_p.npy', np.array(shap_values, dtype=object), allow_pickle=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
