{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f15dd654",
   "metadata": {},
   "source": [
    "- first part of codebase: model dict, pred loop etc\n",
    "- get model output\n",
    "- on public data (=codebase) and on private data\n",
    "- TODO check model outputs, not correlated as of now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8ba374e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture output\n",
    "!pip install --upgrade pip\n",
    "!pip install --upgrade pandas\n",
    "!pip install tables   \n",
    "# necessary for pd.read_hdf()\n",
    "\n",
    "!pip install ipywidgets\n",
    "!pip install --upgrade jupyter\n",
    "!pip install IProgress\n",
    "!pip install catboost\n",
    "!pip install shap\n",
    "!pip install anndata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89882819",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import anndata as ad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea17a10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from tqdm.notebook import tqdm\n",
    "import pickle\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else 'cpu'\n",
    "# pd.set_option('display.max_rows', 500)\n",
    "# pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ad44d6",
   "metadata": {},
   "source": [
    "## data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca3c3ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "lrz_path = '/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93zoj/open-problems-multimodal-3rd-solution/'\n",
    "\n",
    "# model_path_for_now = '/dss/dsshome1/02/di93zoj/valentina/open-problems-multimodal-3rd-solution/'\n",
    "\n",
    "raw_path =  lrz_path + 'input/raw/'  # '../../../input/raw/'\n",
    "\n",
    "cite_target_path = lrz_path + 'input/target/cite/'   # '../../../input/target/cite/'\n",
    "cite_feature_path = lrz_path + 'input/features/cite/'   # '../../../input/features/cite/'\n",
    "cite_mlp_path = lrz_path + 'model/cite/mlp/'   # '../../../model/cite/mlp/'   # '../../../model/cite/mlp/'\n",
    "cite_cb_path = lrz_path + 'model/cite/cb/'   # '../../../model/cite/cb/'\n",
    "\n",
    "# multi_target_path = lrz_path + 'input/target/multi/'   # '../../../input/target/multi/'\n",
    "# multi_feature_path = lrz_path + 'input/features/multi/'   # '../../../input/features/multi/'\n",
    "# multi_mlp_path = lrz_path + 'model/multi/mlp/'   # '../../../model/multi/mlp/'\n",
    "# multi_cb_path = lrz_path + 'model/multi/cb/'   # '../../../model/multi/cb/'\n",
    "\n",
    "index_path = lrz_path + 'input/preprocess/cite/'\n",
    "\n",
    "output_path = lrz_path + 'output/'   # '../../../output/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3f7245",
   "metadata": {},
   "source": [
    "## Cite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab11c66b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get model name\n",
    "#mlp_model_path = os.listdir(cite_mlp_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "276edf07",
   "metadata": {},
   "source": [
    "markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7833a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check model names and lists/dict/..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f531879",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_model_name = [\n",
    "    'corr_add_con_imp',\n",
    "    'corr_last_v3', \n",
    "    'corr_c_add_w2v_v1_mish_flg',\n",
    "    'corr_c_add_w2v_v1_flg',\n",
    "    'corr_c_add_84_v1',\n",
    "    'corr_c_add_120_v1',\n",
    "    'corr_w2v_cell_flg',\n",
    "    'corr_best_cell_120',\n",
    "    'corr_cluster_cell',\n",
    "    'corr_w2v_128',\n",
    "    'corr_imp_w2v_128',\n",
    "    'corr_snorm',\n",
    "    'corr_best_128',\n",
    "    'corr_best_64',\n",
    "    'corr_cluster_128',\n",
    "    'corr_cluster_64',\n",
    "    'corr_svd_128',\n",
    "    'corr_svd_64',\n",
    "             ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7df768e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name_list = []\n",
    "\n",
    "for i in mlp_model_name:\n",
    "    for num, j in enumerate(os.listdir(cite_mlp_path)):\n",
    "        if i in j:\n",
    "            model_name_list.append(j)\n",
    "\n",
    "len(model_name_list)\n",
    "model_name_list   # TODO why not listdir(cite_mlp_path) directly? always 18 models... does mlp_model_name list come from somewhere else?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318f956a",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight = [1, 0.3, 1, 1, 1, 1, 1, 1, 1, 0.8, 0.8, 0.8, 0.8, 0.5, 0.5, 0.5, 1, 1, 2, 2]\n",
    "weight_sum = np.array(weight).sum()    # == 19\n",
    "\n",
    "# model_feat_dict = {model_name_list[0]:['X_test_add_con_imp.pickle', 1],\n",
    "#                    model_name_list[1]:['X_test_last_v3.pickle', 0.3],\n",
    "#                    model_name_list[2]:['X_test_c_add_w2v_v1.pickle', 1],\n",
    "#                    model_name_list[3]:['X_test_c_add_w2v_v1.pickle', 1],\n",
    "#                    model_name_list[4]:['X_test_c_add_84_v1.pickle', 1],\n",
    "#                    model_name_list[5]:['X_test_c_add_v1.pickle', 1],\n",
    "                   \n",
    "#                    model_name_list[6]:['X_test_feature_w2v_cell.pickle', 1],\n",
    "#                    model_name_list[7]:['X_test_best_cell_128_120.pickle', 1],\n",
    "#                    model_name_list[8]:['X_test_cluster_cell_128.pickle', 1],\n",
    "                   \n",
    "#                    model_name_list[9]:['X_test_feature_w2v.pickle', 0.8],\n",
    "#                    model_name_list[10]:['X_test_feature_imp_w2v.pickle',0.8],\n",
    "#                    model_name_list[11]:['X_test_feature_snorm.pickle', 0.8],\n",
    "#                    model_name_list[12]:['X_test_best_128.pickle', 0.8],\n",
    "#                    model_name_list[13]:['X_test_best_64.pickle', 0.5],\n",
    "#                    model_name_list[14]:['X_test_cluster_128.pickle', 0.5],\n",
    "#                    model_name_list[15]:['X_test_cluster_64.pickle', 0.5],\n",
    "#                    model_name_list[16]:['X_test_svd_128.pickle', 1],\n",
    "#                    model_name_list[17]:['X_test_svd_64.pickle', 1],\n",
    "                   \n",
    "#                    'best_128':['X_test_best_128.pickle', 2],\n",
    "#                    'best_64':['X_test_best_64.pickle', 2],\n",
    "#                   }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd09c97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create list of file names to have model_feat_dict in a cleaner way... but is it still readable? TODO\n",
    "file_names = ['X_test_add_con_imp.pickle',\n",
    " 'X_test_last_v3.pickle',\n",
    " 'X_test_c_add_w2v_v1.pickle',\n",
    " 'X_test_c_add_w2v_v1.pickle',\n",
    " 'X_test_c_add_84_v1.pickle',\n",
    " 'X_test_c_add_v1.pickle',\n",
    " 'X_test_feature_w2v_cell.pickle',\n",
    " 'X_test_best_cell_128_120.pickle',\n",
    " 'X_test_cluster_cell_128.pickle',\n",
    " 'X_test_feature_w2v.pickle',\n",
    " 'X_test_feature_imp_w2v.pickle',\n",
    " 'X_test_feature_snorm.pickle',\n",
    " 'X_test_best_128.pickle',\n",
    " 'X_test_best_64.pickle',\n",
    " 'X_test_cluster_128.pickle',\n",
    " 'X_test_cluster_64.pickle',\n",
    " 'X_test_svd_128.pickle',\n",
    " 'X_test_svd_64.pickle',\n",
    " 'X_test_best_128.pickle',\n",
    " 'X_test_best_64.pickle']\n",
    "\n",
    "model_feat_dict = {name: [file_name, weight] for name, weight, file_name in zip(model_name_list+['best_128', 'best_64'], weight, file_names)}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c314bfa",
   "metadata": {},
   "source": [
    "### cite model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "344990cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def std(x):\n",
    "    x = np.array(x)\n",
    "    return (x - x.mean(1).reshape(-1, 1)) / x.std(1).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a4f042",
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CiteDataset(Dataset):\n",
    "    \n",
    "#     def __init__(self, feature, target):\n",
    "        \n",
    "#         self.feature = feature\n",
    "#         self.target = target\n",
    "        \n",
    "#     def __len__(self):\n",
    "#         return len(self.feature)\n",
    "    \n",
    "#     def __getitem__(self, index):\n",
    "                \n",
    "#         d = {\n",
    "#             \"X\": self.feature[index],\n",
    "#             \"y\" : self.target[index],\n",
    "#         }\n",
    "#         return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b14054",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CiteDataset_test(Dataset):\n",
    "    \n",
    "    def __init__(self, feature):\n",
    "        self.feature = feature\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.feature)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "                \n",
    "        d = {\n",
    "            \"X\": self.feature[index]\n",
    "        }\n",
    "        return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a6c349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def partial_correlation_score_torch_faster(y_true, y_pred):\n",
    "#     \"\"\"Compute the correlation between each rows of the y_true and y_pred tensors.\n",
    "#     Compatible with backpropagation.\n",
    "#     \"\"\"\n",
    "#     y_true_centered = y_true - torch.mean(y_true, dim=1)[:,None]\n",
    "#     y_pred_centered = y_pred - torch.mean(y_pred, dim=1)[:,None]\n",
    "#     cov_tp = torch.sum(y_true_centered*y_pred_centered, dim=1)/(y_true.shape[1]-1)\n",
    "#     var_t = torch.sum(y_true_centered**2, dim=1)/(y_true.shape[1]-1)\n",
    "#     var_p = torch.sum(y_pred_centered**2, dim=1)/(y_true.shape[1]-1)\n",
    "#     return cov_tp/torch.sqrt(var_t*var_p)\n",
    "\n",
    "# def correl_loss(pred, tgt):\n",
    "#     \"\"\"Loss for directly optimizing the correlation.\n",
    "#     \"\"\"\n",
    "#     return -torch.mean(partial_correlation_score_torch_faster(tgt, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25f5519",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CiteModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, feature_num):\n",
    "        super(CiteModel, self).__init__()\n",
    "        \n",
    "        self.layer_seq_256 = nn.Sequential(nn.Linear(feature_num, 256),\n",
    "                                           nn.Linear(256, 128),\n",
    "                                       nn.LayerNorm(128),\n",
    "                                       nn.ReLU(),\n",
    "                                      )\n",
    "        self.layer_seq_64 = nn.Sequential(nn.Linear(128, 64),\n",
    "                                       nn.Linear(64, 32),\n",
    "                                       nn.LayerNorm(32),\n",
    "                                       nn.ReLU(),\n",
    "                                      )\n",
    "        self.layer_seq_8 = nn.Sequential(nn.Linear(32, 16),\n",
    "                                         nn.Linear(16, 8),\n",
    "                                       nn.LayerNorm(8),\n",
    "                                       nn.ReLU(),\n",
    "                                      )\n",
    "        \n",
    "        self.head = nn.Linear(128 + 32 + 8, 140)\n",
    "                   \n",
    "    def forward(self, X, y=None):\n",
    "        \n",
    "        from_numpy = False\n",
    "        \n",
    "      ##\n",
    "        if isinstance(X, np.ndarray):\n",
    "            X = torch.from_numpy(X)\n",
    "            from_numpy = True\n",
    "        X = X.to(device)  # Move the input to the appropriate device if necessary\n",
    "        ##\n",
    "        X_256 = self.layer_seq_256(X)\n",
    "        X_64 = self.layer_seq_64(X_256)\n",
    "        X_8 = self.layer_seq_8(X_64)\n",
    "        \n",
    "        X = torch.cat([X_256, X_64, X_8], axis = 1)\n",
    "        out = self.head(X)\n",
    "        \n",
    "        if from_numpy:\n",
    "            out = out.cpu().detach().numpy()\n",
    "            \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4c878b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CiteModel_mish(nn.Module):\n",
    "    \n",
    "    def __init__(self, feature_num):\n",
    "        super(CiteModel_mish, self).__init__()\n",
    "        \n",
    "        self.layer_seq_256 = nn.Sequential(nn.Linear(feature_num, 256),\n",
    "                                           nn.Linear(256, 128),\n",
    "                                       nn.LayerNorm(128),\n",
    "                                       nn.Mish(),\n",
    "                                      )\n",
    "        self.layer_seq_64 = nn.Sequential(nn.Linear(128, 64),\n",
    "                                       nn.Linear(64, 32),\n",
    "                                       nn.LayerNorm(32),\n",
    "                                       nn.Mish(),\n",
    "                                      )\n",
    "        self.layer_seq_8 = nn.Sequential(nn.Linear(32, 16),\n",
    "                                         nn.Linear(16, 8),\n",
    "                                       nn.LayerNorm(8),\n",
    "                                       nn.Mish(),\n",
    "                                      )\n",
    "        \n",
    "        self.head = nn.Linear(128 + 32 + 8, 140)\n",
    "                   \n",
    "    def forward(self, X, y=None):\n",
    "    \n",
    "        X_256 = self.layer_seq_256(X)\n",
    "        X_64 = self.layer_seq_64(X_256)\n",
    "        X_8 = self.layer_seq_8(X_64)\n",
    "        \n",
    "        X = torch.cat([X_256, X_64, X_8], axis = 1)\n",
    "        out = self.head(X)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e14ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_loop(model, optimizer, loader, epoch):\n",
    "    \n",
    "#     losses, lrs = [], []\n",
    "#     model.train()\n",
    "#     optimizer.zero_grad()\n",
    "#     #loss_fn = nn.MSELoss()\n",
    "    \n",
    "#     with tqdm(total=len(loader),unit=\"batch\") as pbar:\n",
    "#         pbar.set_description(f\"Epoch{epoch}\")\n",
    "        \n",
    "#         for d in loader:\n",
    "#             X = d['X'].to(device)\n",
    "#             y = d['y'].to(device)\n",
    "            \n",
    "#             logits = model(X)\n",
    "#             loss = correl_loss(logits, y)\n",
    "#             #loss = torch.sqrt(loss_fn(logits, y))\n",
    "        \n",
    "#             optimizer.zero_grad()\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "            \n",
    "#             pbar.set_postfix({\"loss\":loss.item()})\n",
    "#             pbar.update(1)\n",
    "\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a4774a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def valid_loop(model, loader, y_val):\n",
    "    \n",
    "#     model.eval()\n",
    "#     partial_correlation_scores = []\n",
    "#     oof_pred = []\n",
    "    \n",
    "#     for d in loader:\n",
    "#         with torch.no_grad():\n",
    "#             val_X = d['X'].to(device).float()\n",
    "#             val_y = d['y'].to(device)\n",
    "#             logits = model(val_X)\n",
    "#             oof_pred.append(logits)\n",
    "    \n",
    "#     #print(torch.cat(oof_pred).shape, torch.cat(oof_pred).detach().cpu().numpy().shape)\n",
    "#     cor = partial_correlation_score_torch_faster(torch.tensor(y_val).to(device), torch.cat(oof_pred))\n",
    "#     cor = cor.mean().item()\n",
    "#     logits = torch.cat(oof_pred).detach().cpu().numpy()\n",
    "    \n",
    "#     return logits, cor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "278d0d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(model, loader):\n",
    "    \n",
    "    model.eval()\n",
    "    predicts=[]\n",
    "\n",
    "    for d in tqdm(loader):\n",
    "        with torch.no_grad():\n",
    "            X = d['X'].to(device)\n",
    "            logits = model(X)\n",
    "            predicts.append(logits.detach().cpu().numpy())\n",
    "            \n",
    "    return np.concatenate(predicts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa8754e6",
   "metadata": {},
   "source": [
    "### ensemble prediction: use all models, sum weighted predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6dfa7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pred = np.zeros([48203, 140])\n",
    "\n",
    "for num, i in enumerate(model_feat_dict.keys()):\n",
    "    \n",
    "    print(i)\n",
    "    \n",
    "    if 'mlp' in i:\n",
    "\n",
    "        try:\n",
    "            test_file = model_feat_dict[i][0]\n",
    "            test_weight = model_feat_dict[i][1]\n",
    "            X_test = pd.read_pickle(cite_feature_path  + test_file)   \n",
    "            # print(cite_feature_path  + test_file)\n",
    "            X_test = np.array(X_test)\n",
    "            feature_dims = X_test.shape[1]\n",
    "\n",
    "            test_ds = CiteDataset_test(X_test)\n",
    "            test_dataloader = DataLoader(test_ds, batch_size=128, pin_memory=True, \n",
    "                                         shuffle=False, drop_last=False, num_workers=4)\n",
    "\n",
    "            if 'mish' in i:\n",
    "                model = CiteModel_mish(feature_dims)\n",
    "            else:\n",
    "                model = CiteModel(feature_dims)\n",
    "\n",
    "            model = model.to(device)\n",
    "            model.load_state_dict(torch.load(f'{cite_mlp_path}/{i}'))\n",
    "\n",
    "            result = test_loop(model, test_dataloader).astype(np.float32)\n",
    "            result = std(result) * test_weight / weight_sum\n",
    "            pred += result\n",
    "\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        except Exception as e: \n",
    "            print(i)\n",
    "            print(e)             # TODOOOOOOOOOOOOOO\n",
    "        \n",
    "    else:\n",
    "        test_file = model_feat_dict[i][0]\n",
    "        test_weight = model_feat_dict[i][1]\n",
    "        X_test = pd.read_pickle(cite_feature_path  + test_file)\n",
    "        \n",
    "        cb_pred = np.zeros([48203, 140])\n",
    "        \n",
    "        for t in tqdm(range(140)): \n",
    "            cb_model_path = [j for j in os.listdir(cite_cb_path) if f'cb_{t}_{i}' in j][0]\n",
    "            cb = pickle.load(open(cite_cb_path + cb_model_path, 'rb'))\n",
    "            cb_pred[:,t] = cb.predict(X_test)\n",
    "            \n",
    "        cb_pred = cb_pred.astype(np.float32)\n",
    "        pred += std(cb_pred) * test_weight / weight_sum\n",
    "        \n",
    "        del cb_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c80adf38",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05121ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO check pred / target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd5929b6",
   "metadata": {},
   "source": [
    "### pred loop function (only for single models, not ensemble)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48a4937e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pred(model_name, X_test=None): \n",
    "\n",
    "    '''if test file from model_feat_dict: pass X_test=None\n",
    "    if other test file, e.g. private test data, pass it as param '''\n",
    "\n",
    "\n",
    "    # pred = np.zeros([rows, cols])\n",
    "    if X_test is None:\n",
    "        test_file = model_feat_dict[model_name][0]\n",
    "        X_test = np.array(pd.read_pickle(cite_feature_path + test_file))\n",
    "    \n",
    "    feature_dims = X_test.shape[1]\n",
    "    print(feature_dims)\n",
    "\n",
    "    test_ds = CiteDataset_test(np.array(X_test))\n",
    "    test_dataloader = DataLoader(test_ds, batch_size=128, pin_memory=True, \n",
    "                                shuffle=False, drop_last=False, num_workers=4)\n",
    "\n",
    "    if 'mish' in model_name:\n",
    "        model = CiteModel_mish(feature_dims)\n",
    "    else:\n",
    "        model = CiteModel(feature_dims)\n",
    "        \n",
    "    model = model.to(device)\n",
    "    model.load_state_dict(torch.load(f'{cite_mlp_path}/{model_name}'))\n",
    "\n",
    "    pred = test_loop(model, test_dataloader).astype(np.float32)\n",
    "   \n",
    "    torch.cuda.empty_cache()\n",
    "            \n",
    "    return pd.DataFrame(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac73d442",
   "metadata": {},
   "source": [
    "use for model 16:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7dac3dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model #16: cite_mlp_corr_svd_128_flg_donor_val_30\n",
    "get_pred('cite_mlp_corr_svd_128_flg_donor_val_30')\n",
    "\n",
    "# double check train_cite_targets.h5  -> omnipath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca7e3e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_hdf('/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93zoj/neurips_competition_data/train_cite_targets.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0926a6c",
   "metadata": {},
   "source": [
    "use for model 17:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b67701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model #17: 'cite_mlp_corr_svd_64_flg_donor_val_38'\n",
    "get_pred('cite_mlp_corr_svd_64_flg_donor_val_38')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21837b08",
   "metadata": {},
   "source": [
    "### prediction with private test input -> should get private test target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a2d5e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "private_test_input = ad.read('/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93zoj/large_preprocessed_files/private_test_input.h5ad')\n",
    "private_test_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ab1abd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "private_test_target = ad.read('/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93zoj/large_preprocessed_files/private_test_target.h5ad')\n",
    "private_test_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d65e1d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# private_test_input.to_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b6f714",
   "metadata": {},
   "outputs": [],
   "source": [
    "# should be non-raw df (non-int)\n",
    "# private_test_target_raw = ad.read('/dss/dssfs02/lwp-dss-0001/pn36po/pn36po-dss-0001/di93zoj/large_preprocessed_files/private_test_target_raw.h5ad')\n",
    "# private_test_target_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "665eb509",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "with open('private_X_test_svd.pkl', 'rb') as f:  # private_X_test_svd\n",
    "\n",
    "    private_X_test_svd = pickle.load(f)\n",
    "private_X_test_svd.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb66319",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('private_X_test_svd_from_raw.pkl', 'rb') as f:  # private_X_test_svd\n",
    "\n",
    "#     private_X_test_svd_from_raw = pickle.load(f)\n",
    "# private_X_test_svd_from_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee38efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get model #16 prediction on private test data\n",
    "# model #16: cite_mlp_corr_svd_128_flg_donor_val_30\n",
    "\n",
    "pred_private = get_pred('cite_mlp_corr_svd_128_flg_donor_val_30', private_X_test_svd)\n",
    "print(pred_private.shape)\n",
    "pred_private.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df054b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(private_test_target.X).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbd60bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(private_test_target_raw.X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e27cb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([pd.DataFrame(pred_private), pd.DataFrame(private_test_target.X)]).corr().head()   # TODO is this correct? this compares all columns but not both datasets?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
